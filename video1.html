<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>NVIDIA B300 Blackwell Ultra — Technical Deep Dive</title>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/dist/reveal.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/dist/theme/black.css">
<style>
  :root {
    --accent: #76b900;       /* NVIDIA green */
    --accent2: #0080ff;      /* DigitalOcean-ish blue */
    --bg-dark: #0d1117;
    --text-muted: #8b949e;
  }
  .reveal { font-family: 'Segoe UI', system-ui, -apple-system, sans-serif; }
  .reveal h1, .reveal h2, .reveal h3 { color: var(--accent); text-transform: none; font-weight: 700; }
  .reveal h1 { font-size: 2.2em; }
  .reveal h2 { font-size: 1.6em; }
  .reveal h3 { font-size: 1.2em; color: var(--accent2); }
  .reveal p, .reveal li { font-size: 0.75em; line-height: 1.6; }
  .reveal .subtitle { color: var(--text-muted); font-size: 0.9em; margin-top: -0.3em; }
  .reveal table { font-size: 0.65em; margin: 0.5em auto; border-collapse: collapse; }
  .reveal table th { background: rgba(118,185,0,0.15); color: var(--accent); padding: 0.4em 0.8em; border-bottom: 2px solid var(--accent); }
  .reveal table td { padding: 0.35em 0.8em; border-bottom: 1px solid #333; }
  .reveal table tr:last-child td { border-bottom: none; }
  .reveal .highlight { color: var(--accent); font-weight: 700; }
  .reveal .stat-grid { display: flex; justify-content: center; gap: 2em; margin: 1em 0; flex-wrap: wrap; }
  .reveal .stat-box { text-align: center; padding: 0.8em 1.2em; border: 2px solid var(--accent); border-radius: 12px; min-width: 160px; }
  .reveal .stat-box .number { font-size: 2em; font-weight: 800; color: var(--accent); display: block; }
  .reveal .stat-box .label { font-size: 0.6em; color: var(--text-muted); }
  .reveal .diagram { background: rgba(255,255,255,0.03); border: 1px solid #333; border-radius: 8px; padding: 1em; font-family: 'Courier New', monospace; font-size: 0.55em; line-height: 1.4; text-align: left; white-space: pre; overflow-x: auto; }
  .reveal .two-col { display: grid; grid-template-columns: 1fr 1fr; gap: 1.5em; align-items: start; }
  .reveal .callout { background: rgba(118,185,0,0.08); border-left: 4px solid var(--accent); padding: 0.6em 1em; border-radius: 0 8px 8px 0; font-size: 0.7em; margin: 0.5em 0; }
  .reveal .red { color: #f85149; }
  .reveal .green { color: #76b900; }
  .reveal .blue { color: var(--accent2); }
  .reveal .amber { color: #d29922; }
  .reveal ul { list-style: none; padding-left: 0; }
  .reveal ul li::before { content: "▸ "; color: var(--accent); font-weight: bold; }
  .reveal .section-title { font-size: 2.5em !important; }
  .reveal .fragment.fade-in-then-semi-out.visible:not(.current-fragment) { opacity: 0.4; }
  .slide-number { font-size: 12px !important; }
</style>
</head>
<body>
<div class="reveal">
<div class="slides">

<!-- ============ SLIDE 1: TITLE ============ -->
<section>
  <h1>NVIDIA B300</h1>
  <h2 style="color: #ccc; font-size: 1.1em;">Blackwell Ultra: Technical Deep Dive</h2>
  <p class="subtitle">The GPU Powering the AI Factory Era</p>
  <br>
  <div class="stat-grid">
    <div class="stat-box"><span class="number">15</span><span class="label">PFLOPS (FP4)</span></div>
    <div class="stat-box"><span class="number">288</span><span class="label">GB HBM3e</span></div>
    <div class="stat-box"><span class="number">208B</span><span class="label">Transistors</span></div>
  </div>
</section>

<!-- ============ SLIDE 2: WHY B300 EXISTS ============ -->
<section>
  <h2>The AI Factory Era</h2>
  <p>Models are growing faster than hardware can keep up</p>
  <br>
  <div class="stat-grid">
    <div class="stat-box"><span class="number">175B</span><span class="label">GPT-3 (2020)</span></div>
    <div class="stat-box"><span class="number">1T+</span><span class="label">GPT-4 (2023)</span></div>
    <div class="stat-box"><span class="number">???</span><span class="label">Reasoning Models (2026)</span></div>
  </div>
  <br>
  <div class="callout">
    The best models today <span class="highlight">do not fit</span> on a single GPU.<br>
    Split across GPUs → more hardware, more complexity, more cost.
  </div>
</section>

<!-- ============ SLIDE 3: GPU EVOLUTION ============ -->
<section>
  <h2>GPU Evolution</h2>
  <table>
    <tr><th>Year</th><th>GPU</th><th>Architecture</th><th>AI Compute</th><th>Memory</th></tr>
    <tr class="fragment"><td>2020</td><td>A100</td><td>Ampere</td><td>0.6 PFLOPS</td><td>80 GB</td></tr>
    <tr class="fragment"><td>2022</td><td>H100</td><td>Hopper</td><td>2 PFLOPS</td><td>80 GB</td></tr>
    <tr class="fragment"><td>2024</td><td>B200</td><td>Blackwell</td><td>10 PFLOPS</td><td>192 GB</td></tr>
    <tr class="fragment" style="color: var(--accent); font-weight: 700;"><td>2025</td><td>B300</td><td>Blackwell Ultra</td><td>15 PFLOPS</td><td>288 GB</td></tr>
  </table>
  <p class="fragment" style="margin-top: 1em;"><span class="highlight">7.5x</span> compute and <span class="highlight">3.6x</span> memory vs. H100 in 3 years</p>
</section>

<!-- ============ SLIDE 4: THE NUMBERS ============ -->
<section>
  <h2>B300 vs B200 vs H100</h2>
  <table>
    <tr><th>Metric</th><th>H100</th><th>B200</th><th style="color: var(--accent);">B300</th></tr>
    <tr><td>FP4 Dense</td><td>2 PFLOPS*</td><td>10 PFLOPS</td><td class="highlight">15 PFLOPS</td></tr>
    <tr><td>HBM3e Memory</td><td>80 GB</td><td>192 GB</td><td class="highlight">288 GB</td></tr>
    <tr><td>Memory Bandwidth</td><td>3.35 TB/s</td><td>8 TB/s</td><td class="highlight">8 TB/s</td></tr>
    <tr><td>NVLink BW</td><td>900 GB/s</td><td>1,800 GB/s</td><td class="highlight">1,800 GB/s</td></tr>
    <tr><td>TDP</td><td>700W</td><td>1,200W</td><td class="amber">1,400W</td></tr>
  </table>
  <p style="font-size: 0.55em; color: var(--text-muted);">*H100 equivalent with INT8/FP8</p>
</section>

<!-- ============ SLIDE 5: DUAL RETICLE ============ -->
<section>
  <h2>Dual-Reticle Architecture</h2>
  <p>Two dies. One GPU. 208 billion transistors.</p>
  <br>
  <div style="display: flex; justify-content: center; align-items: center; gap: 0;">
    <!-- Die A -->
    <div style="border: 2px solid var(--accent); border-radius: 10px; padding: 0.8em 1.2em; text-align: center; min-width: 180px; background: rgba(118,185,0,0.05);">
      <div style="font-size: 1em; font-weight: 700; color: var(--accent);">Die A</div>
      <div style="font-size: 0.55em; color: var(--text-muted); margin-top: 0.3em;">104B transistors<br>80 SMs · 320 Tensor Cores</div>
    </div>
    <!-- NV-HBI arrow -->
    <div style="display: flex; flex-direction: column; align-items: center; padding: 0 0.8em;">
      <div style="font-size: 0.55em; color: var(--accent); font-weight: 700;">NV-HBI</div>
      <div style="font-size: 1.5em; color: var(--accent); letter-spacing: -2px;">◄──►</div>
      <div style="font-size: 0.55em; color: var(--accent); font-weight: 700;">10 TB/s</div>
    </div>
    <!-- Die B -->
    <div style="border: 2px solid var(--accent); border-radius: 10px; padding: 0.8em 1.2em; text-align: center; min-width: 180px; background: rgba(118,185,0,0.05);">
      <div style="font-size: 1em; font-weight: 700; color: var(--accent);">Die B</div>
      <div style="font-size: 0.55em; color: var(--text-muted); margin-top: 0.3em;">104B transistors<br>80 SMs · 320 Tensor Cores</div>
    </div>
  </div>
  <br>
  <!-- Unified L2 -->
  <div style="max-width: 500px; margin: 0 auto;">
    <div style="border: 1px solid var(--accent2); border-radius: 6px; padding: 0.3em; text-align: center; font-size: 0.6em; color: var(--accent2); background: rgba(0,128,255,0.05);">
      Unified L2 Cache: 50 MB
    </div>
  </div>
  <!-- HBM3e -->
  <div style="display: flex; justify-content: center; gap: 0.4em; margin-top: 0.6em;">
    <div style="background: var(--accent); border-radius: 3px; padding: 0.2em 0.5em; font-size: 0.45em; color: #000; font-weight: 700;">36 GB</div>
    <div style="background: var(--accent); border-radius: 3px; padding: 0.2em 0.5em; font-size: 0.45em; color: #000; font-weight: 700;">36 GB</div>
    <div style="background: var(--accent); border-radius: 3px; padding: 0.2em 0.5em; font-size: 0.45em; color: #000; font-weight: 700;">36 GB</div>
    <div style="background: var(--accent); border-radius: 3px; padding: 0.2em 0.5em; font-size: 0.45em; color: #000; font-weight: 700;">36 GB</div>
    <div style="background: var(--accent); border-radius: 3px; padding: 0.2em 0.5em; font-size: 0.45em; color: #000; font-weight: 700;">36 GB</div>
    <div style="background: var(--accent); border-radius: 3px; padding: 0.2em 0.5em; font-size: 0.45em; color: #000; font-weight: 700;">36 GB</div>
    <div style="background: var(--accent); border-radius: 3px; padding: 0.2em 0.5em; font-size: 0.45em; color: #000; font-weight: 700;">36 GB</div>
    <div style="background: var(--accent); border-radius: 3px; padding: 0.2em 0.5em; font-size: 0.45em; color: #000; font-weight: 700;">36 GB</div>
  </div>
  <p style="font-size: 0.5em; color: var(--text-muted); margin-top: 0.3em;">8× HBM3e stacks = 288 GB @ 8 TB/s</p>
  <p class="fragment callout">Appears as a <span class="highlight">single CUDA device</span> — transparent to developers</p>
</section>

<!-- ============ SLIDE 6: TENSOR CORES ============ -->
<section>
  <h2>5th-Gen Tensor Cores</h2>
  <div class="two-col">
    <div>
      <h3>Evolution</h3>
      <table>
        <tr><th>Gen</th><th>Arch</th><th>Innovation</th></tr>
        <tr><td>1st</td><td>Volta</td><td>Matrix multiply</td></tr>
        <tr><td>2nd</td><td>Turing</td><td>INT8, INT4</td></tr>
        <tr><td>3rd</td><td>Ampere</td><td>TF32, sparsity</td></tr>
        <tr><td>4th</td><td>Hopper</td><td>FP8, Transformer Engine</td></tr>
        <tr style="color: var(--accent);"><td>5th</td><td>Blackwell</td><td>NVFP4, 2x attention</td></tr>
      </table>
    </div>
    <div>
      <h3>What's New</h3>
      <ul>
        <li class="fragment">Native <span class="highlight">NVFP4</span> support</li>
        <li class="fragment"><span class="highlight">2x</span> attention acceleration (softmax)</li>
        <li class="fragment"><span class="highlight">Tensor Memory</span> (256 KB/SM)</li>
        <li class="fragment">Dual-Thread-Block MMA</li>
      </ul>
    </div>
  </div>
</section>

<!-- ============ SLIDE 7: NVFP4 ============ -->
<section>
  <h2>NVFP4: The Precision Revolution</h2>
  <p>4-bit floating point with two-level scaling</p>
  <br>
  <table>
    <tr><th>Format</th><th>Bits/Weight</th><th>Memory Use</th><th>Compute</th><th>Accuracy Loss</th></tr>
    <tr><td>FP16</td><td>16</td><td>1x</td><td>1x</td><td>0%</td></tr>
    <tr><td>FP8</td><td>8</td><td>0.5x</td><td>2x</td><td>~0.5%</td></tr>
    <tr style="color: var(--accent); font-weight: 700;"><td>NVFP4</td><td>4</td><td>~0.29x (~3.5x savings)</td><td>4x</td><td>~1%</td></tr>
  </table>
  <br>
  <div class="callout fragment">
    <strong>DeepSeek-R1 671B:</strong> 1,342 GB in FP16 → <span class="highlight">~383 GB in NVFP4</span>
  </div>
  <br>
  <table class="fragment" style="font-size: 0.6em;">
    <tr><th>GPU</th><th>Precision</th><th>Model Size</th><th>GPUs Needed</th></tr>
    <tr><td>H100 (80 GB)</td><td>FP16</td><td>1,342 GB</td><td class="red">17</td></tr>
    <tr><td>H100 (80 GB)</td><td>FP8</td><td>~671 GB</td><td class="red">9</td></tr>
    <tr style="color: var(--accent); font-weight: 700;"><td>B300 (288 GB)</td><td>NVFP4</td><td>~383 GB</td><td>2</td></tr>
  </table>
</section>

<!-- ============ SLIDE 8: MEMORY ARCHITECTURE ============ -->
<section>
  <h2>288 GB HBM3e</h2>
  <p style="margin-bottom: 0.2em;">8× 12-Hi stacks · 8 TB/s bandwidth · 8,192-bit interface</p>
  <br>
  <div class="callout">
    8 TB/s bandwidth feeds data to tensor cores fast enough to keep up with compute.
  </div>
  <br>
  <div class="two-col">
    <div>
      <h3>Why It Matters</h3>
      <ul>
        <li class="fragment"><span class="highlight">Larger models</span> on fewer GPUs</li>
        <li class="fragment"><span class="highlight">Bigger KV caches</span> → longer context</li>
        <li class="fragment"><span class="highlight">Higher batch sizes</span> → better throughput</li>
        <li class="fragment"><span class="highlight">Lower cost</span> per inference</li>
      </ul>
    </div>
    <div>
      <h3>Frame of Reference</h3>
      <p style="font-size: 0.65em;">DeepSeek-R1 671B in NVFP4: ~383 GB<br>→ Fits on <span class="highlight">2 B300s</span> vs 9 H100s</p>
    </div>
  </div>
</section>

<!-- ============ SLIDE 9: NVLINK & SCALE ============ -->
<section>
  <h2>Multi-GPU Scaling</h2>
  <p>8× B300 GPUs + Intel Xeon CPUs + 2 TB system memory</p>
  <br>
  <div class="stat-grid">
    <div class="stat-box"><span class="number">2.3 TB</span><span class="label">GPU Memory</span></div>
    <div class="stat-box"><span class="number">108</span><span class="label">PFLOPS FP4 Dense</span></div>
    <div class="stat-box"><span class="number">~14 kW</span><span class="label">System Power</span></div>
  </div>
  <br>
  <div class="two-col fragment">
    <div class="callout">
      <strong>Intra-node: NVLink 5</strong><br>
      2× NVSwitch (5th gen)<br>
      14.4 TB/s aggregate, 1,800 GB/s per GPU<br>
      2x faster than Hopper generation
    </div>
    <div class="callout">
      <strong>Inter-node: up to 800 Gb/s</strong><br>
      InfiniBand or Ethernet via ConnectX-8<br>
      Standard datacenter networking
    </div>
  </div>
  <p class="fragment" style="font-size: 0.55em; color: var(--text-muted);">144 PFLOPS FP4 sparse | 72 PFLOPS FP8 training</p>
</section>

<!-- ============ SLIDE 10: INFERENCE PERFORMANCE ============ -->
<section>
  <h2>Performance — Official NVIDIA Claims</h2>
  <p>B300 vs. previous generations</p>
  <br>
  <div class="stat-grid">
    <div class="stat-box"><span class="number">1.5x</span><span class="label">vs B200 (NVFP4)</span></div>
    <div class="stat-box"><span class="number">7.5x</span><span class="label">vs H100 (FP8)</span></div>
  </div>
  <br>
  <div class="callout fragment">
    <strong>8-GPU System Level</strong><br>
    <span class="highlight">11x</span> faster LLM inference vs Hopper &nbsp;|&nbsp;
    <span class="highlight">7x</span> more compute &nbsp;|&nbsp;
    <span class="highlight">4x</span> more memory
  </div>
  <br>
  <div class="callout fragment">
    <strong>Efficiency:</strong> <span class="highlight">5x</span> higher throughput per megawatt vs Hopper
  </div>
</section>

<!-- ============ SLIDE 11: EFFICIENCY ============ -->
<section>
  <h2>Efficiency & Power</h2>
  <p>More AI throughput per watt</p>
  <br>
  <div class="stat-grid">
    <div class="stat-box"><span class="number">5x</span><span class="label">Throughput/MW vs Hopper</span></div>
    <div class="stat-box"><span class="number">1,400W</span><span class="label">TDP per GPU</span></div>
  </div>
  <br>
  <div class="callout fragment">
    <strong>The trade-off:</strong> Higher power draw per GPU, but <span class="highlight">disproportionately more output</span>.<br>
    More power in → far more AI throughput out. Air-cooled configs available; liquid cooling for higher-density deployments.
  </div>
  <br>
  <div class="callout fragment">
    <strong>8-GPU node:</strong> 108 PFLOPS FP4 dense, with 2.3 TB of unified GPU memory.
  </div>
</section>

<!-- ============ SLIDE 12: END ============ -->
<section>
  <h1 style="font-size: 2em;">Thank You</h1>
  <br>
  <p class="subtitle">NVIDIA B300 Blackwell Ultra — Technical Deep Dive</p>
  <br>
  <p style="font-size: 0.7em;">Next video: <span class="highlight">Should You Switch to B300?</span></p>
  <br>
  <p style="font-size: 0.6em; color: var(--text-muted);">
    Sources: NVIDIA Developer Blog, NVIDIA Newsroom, NVIDIA NVFP4 Blog
  </p>
</section>

</div><!-- /slides -->
</div><!-- /reveal -->

<script src="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/dist/reveal.js"></script>
<script>
Reveal.initialize({
  hash: true,
  slideNumber: 'c/t',
  transition: 'slide',
  transitionSpeed: 'default',
  backgroundTransition: 'fade',
  center: true,
  width: 1280,
  height: 720,
  margin: 0.08,
  pdfMaxPagesPerSlide: 1,
});
</script>
</body>
</html>
